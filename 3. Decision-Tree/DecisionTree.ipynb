{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Program - 3</h1></center>\n",
    "\n",
    "<center><h3>Decision Tree</h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6  148  72  35    0  33.6  0.627  50  1\n",
      "0  1   85  66  29    0  26.6  0.351  31  0\n",
      "1  8  183  64   0    0  23.3  0.672  32  1\n",
      "2  1   89  66  23   94  28.1  0.167  21  0\n",
      "3  0  137  40  35  168  43.1  2.288  33  1\n",
      "4  5  116  74   0    0  25.6  0.201  30  0\n",
      "Confusion Matrix:\n",
      " [[298 154]\n",
      " [ 95 140]]\n",
      "False Positive \n",
      " 154\n",
      "False Negative \n",
      " 95\n",
      "True Positive \n",
      " 298\n",
      "True Negative \n",
      " 140\n",
      "Senstivity \n",
      " 0.7582697201017812\n",
      "Specificity \n",
      " 0.47619047619047616\n",
      "Precision 0.6592920353982301\n",
      "Recall \n",
      " 0.7582697201017812\n",
      "Accuracy \n",
      " 0.6375545851528385\n",
      "FScore  0.7053254437869823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "dataset=pd.read_csv('pima-indians-diabetes.csv')\n",
    "print(dataset.head())\n",
    "train_features=dataset.iloc[:80,:-1]\n",
    "test_features=dataset.iloc[80:,:-1]\n",
    "train_targets=dataset.iloc[:80,-1]\n",
    "test_targets=dataset.iloc[80:,-1]\n",
    "tree1=DecisionTreeClassifier(criterion='entropy').fit(train_features,train_targets)\n",
    "prediction=tree1.predict(test_features)\n",
    "cm=confusion_matrix(test_targets,prediction)\n",
    "print('Confusion Matrix:\\n',cm)\n",
    "TP=cm[0][0]\n",
    "FP=cm[0][1]\n",
    "FN=cm[1][0]\n",
    "TN=cm[1][1]\n",
    "print('False Positive \\n {}'.format(FP))\n",
    "print('False Negative \\n {}'.format(FN))\n",
    "print('True Positive \\n {}'.format(TP))\n",
    "print('True Negative \\n {}'.format(TN))\n",
    "TPR=TP/(TP+FN)\n",
    "print('Senstivity \\n {}'.format(TPR))\n",
    "TNR=TN/(TN+FP)\n",
    "print('Specificity \\n {}'.format(TNR))\n",
    "Precision=TP/(TP+FP)\n",
    "print('Precision {}'.format(Precision))\n",
    "Recall=TP/(TP+FN)\n",
    "print('Recall \\n {}'.format(Recall))\n",
    "Acc=(TP+TN)/(TP+TN+FP+FN)\n",
    "print('Accuracy \\n {}'.format(Acc))\n",
    "Fscore=2*(Precision*Recall)/(Precision+Recall)\n",
    "print('FScore  {}'.format(Fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
